{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if page downloaded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.dli.pa.gov/Individuals/Workforce-Development/warn/notices/Pages/default.aspx\"\n",
    "page = requests.get(url)\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## webpage url parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "data = soup.findAll('div',attrs={'class':'ms-rtestate-field'})\n",
    "month_links = []\n",
    "for div in data:\n",
    "    links = div.findAll('a')\n",
    "    for a in links:\n",
    "        month_links.append(\"https://www.dli.pa.gov/\"+a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(month_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#month_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## after 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_pattern_unbold(element):\n",
    "    ele = element\n",
    "    data = ele.find_all('p')\n",
    "    if data:\n",
    "        try:\n",
    "            name = re.sub(' +', ' ', \" \".join([data[0].find('strong').text.replace('\\n', ' ')])).strip() \n",
    "        except: \n",
    "            return None\n",
    "        if len(data) != 2:\n",
    "            return name\n",
    "\n",
    "        ad_list = []\n",
    "        #delete the name part\n",
    "        ad_list.append(\", \".join([ele.strip() for ele in re.findall(r'\\>([^\\>]*)\\<', str(data[0]).split(\"</strong>\")[1]) if ele not in ('\\n','')]))\n",
    "\n",
    "        for ad in data[1:-1]:\n",
    "\n",
    "            ad_list.append(\", \".join([ele.strip() for ele in re.findall(r'\\>([^\\>]*)\\<', str(ad)) if ele not in ('\\n','')]))\n",
    "\n",
    "        part1 = \" and \".join(ad_list)\n",
    "\n",
    "        #print(part1)\n",
    "\n",
    "        part2 = \" \".join([ele.strip() for ele in re.findall(r'\\>([^\\>]*)\\<', str(data[-1])) if ele not in ('\\n','')])\n",
    "\n",
    "        string = part1+\" \"+part2\n",
    "        \n",
    "        string = re.sub(' +', ' ', \" \".join([string.replace('\\n', ' ')])).strip()\n",
    "\n",
    "        try:\n",
    "            address = string.split(\"COUNTY:\")[0]\n",
    "\n",
    "            county = string.split(\"COUNTY:\")[1].split(\"# AFFECTED:\")[0]\n",
    "\n",
    "            string = string.replace(\"LAYOFF EFFECTIVE DATES:\", \"EFFECTIVE DATE:\")\n",
    "\n",
    "            string = string.replace(\"LAYOFF EFFECTIVE DATE:\", \"EFFECTIVE DATE:\")\n",
    "\n",
    "            #print(string.split(\"COUNTY:\")[1].split(\"# AFFECTED:\"))\n",
    "\n",
    "            employees_affected = string.split(\"COUNTY:\")[1].split(\"# AFFECTED:\")[1].split(\"EFFECTIVE DATE:\")[0]\n",
    "\n",
    "            string = string.replace(\"CLOSING OR LAYOFF:\", \"CLOSURE OR LAYOFF:\")\n",
    "\n",
    "            effective_date = string.split(\"COUNTY:\")[1].split(\"# AFFECTED:\")[1].split(\"EFFECTIVE DATE:\")[1].split(\"CLOSURE OR LAYOFF:\")[0]\n",
    "\n",
    "\n",
    "\n",
    "            closure_or_layoff = string.split(\"COUNTY:\")[1].split(\"# AFFECTED:\")[1].split(\"EFFECTIVE DATE:\")[1].split(\"CLOSURE OR LAYOFF:\")[1]\n",
    "\n",
    "            return name, address, county, employees_affected, effective_date, closure_or_layoff\n",
    "        except:\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_bold(element):\n",
    "    data = element\n",
    "    if data:\n",
    "        total_text = re.sub(' +', ' ', \" \".join([data.text.replace('\\n', ' ')])).strip()\n",
    "        bold_ele = [re.sub(' +', ' ', ele.text.replace('\\n', ' ')).strip() for ele in data.find_all('strong')]\n",
    "        if bold_ele == []:\n",
    "            return None\n",
    "\n",
    "        name =  bold_ele[0].strip()\n",
    "        #if \"*UPDATE*\" in name:\n",
    "            #return \" \".join(bold_ele)\n",
    "        \n",
    "        for ele in bold_ele:\n",
    "            total_text = total_text.replace(ele, \"@#$%&\")\n",
    "        results = [re.sub(' +', ' ', ele).strip() for ele in total_text.split(\"@#$%&\")]\n",
    "        #remove null elements\n",
    "        results = [ele for ele in results if ele]\n",
    "        #print(bold_ele)\n",
    "        #print(results)\n",
    "        if len(bold_ele) == 4 and len(results) == 4:\n",
    "            #print(bold_ele)\n",
    "            address = results[0]\n",
    "            county = results[1]\n",
    "            employees_affected = results[2]\n",
    "            effective_date = results[3]\n",
    "            closure_or_layoff = \"N/A\"\n",
    "            return name, address, county, employees_affected, effective_date, closure_or_layoff\n",
    "        elif len(bold_ele) == 5 and len(results) == 4:# and bold_ele[3] in ['CLOSURE',\"CLOSING\", \"LAYOFF\",\"PERMANENT CLOSURE\", \"PERMANENT LAYOFF\",\"PERMANENT CLOSING\", \"CONTRACT CANCELLED\",\"PLANT CLOSURE\",\"CONTRACT CANCELLED\",\"PLANT CLOSURE\",\"CLOSURE/PERMANENT LAYOFF\",\"CLOSURE/PENDING SALE\",\"PERMANENT LAYOFFS\"， \"PENDING SALE - CLOSING\"，\"PLANT CLOSING\", \"PENDING SALE - NO LAYOFF\", \"PERMANENT\", \"PERMANENT MASS LAYOFF\" ]:\n",
    "            address = results[0]\n",
    "            county = results[1]\n",
    "            employees_affected = results[2]\n",
    "            effective_date = results[3]\n",
    "            closure_or_layoff = bold_ele[3]\n",
    "            return name, address, county, employees_affected, effective_date, closure_or_layoff\n",
    "        else:\n",
    "            #print(bold_ele)\n",
    "            #print(results)\n",
    "            #print()\n",
    "            return \" \".join(bold_ele[:2])\n",
    "\n",
    "        if name in company_name and effective_date in effective_date_l and address in company_address:\n",
    "            return None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(url):\n",
    "    #\n",
    "    page = requests.get(url)\n",
    "    #store html\n",
    "    url_name = url.split('/')[-1].split('.')[0]\n",
    "    #get year\n",
    "    year = int(url_name.split('-')[1])\n",
    "    with open(os.path.join(dirs, url_name+\".html\"), 'w',encoding = 'utf8') as file:\n",
    "        file.write(page.text)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    table_data = soup.findAll('td')\n",
    "    table_data = [ele for ele in table_data if re.sub(' +', ' ', ele.text).strip()]\n",
    "    #\n",
    "    urls = []\n",
    "    company_name = []\n",
    "    company_address = []\n",
    "    county_l = []\n",
    "    employees_affected_l = []\n",
    "    effective_date_l = []\n",
    "    closure_or_layoff_l = []\n",
    "    \n",
    "    #\n",
    "    error_link = []\n",
    "    error_name = []\n",
    "\n",
    "    for ele in table_data:#[10:11]:\n",
    "        if year < 2016:\n",
    "            result = get_pattern_bold(ele)\n",
    "            if result == None:\n",
    "                continue\n",
    "            if len(result) == 6:\n",
    "\n",
    "                name, address, county, employees_affected, effective_date, closure_or_layoff = result\n",
    "\n",
    "                if name in company_name and effective_date in effective_date_l and address in company_address and county in county_l and employees_affected in employees_affected_l and closure_or_layoff in closure_or_layoff_l:\n",
    "                    continue\n",
    "                \n",
    "                urls.append(url) \n",
    "                \n",
    "                company_name.append(name)\n",
    "\n",
    "                company_address.append(address)\n",
    "\n",
    "                county_l.append(county)\n",
    "\n",
    "                employees_affected_l.append(employees_affected)\n",
    "\n",
    "                effective_date_l.append(effective_date)\n",
    "\n",
    "                closure_or_layoff_l.append(closure_or_layoff)\n",
    "\n",
    "            else:\n",
    "                name = result \n",
    "                error_name.append(name)\n",
    "                error_link.append(url)\n",
    "                continue\n",
    "                \n",
    "        if year > 2016:\n",
    "            result = get_pattern_unbold(ele)\n",
    "            \n",
    "            if result == None:\n",
    "                continue\n",
    "            if len(result) == 6 :\n",
    "\n",
    "                name, address, county, employees_affected, effective_date, closure_or_layoff = result\n",
    "\n",
    "                if name in company_name and effective_date in effective_date_l and address in company_address and county in county_l and employees_affected in employees_affected_l and closure_or_layoff in closure_or_layoff_l:\n",
    "                    continue\n",
    "                if not address:\n",
    "                    name = name\n",
    "                    error_name.append(name)\n",
    "                    error_link.append(url)\n",
    "                    continue                    \n",
    "                urls.append(url) \n",
    "                    \n",
    "                company_name.append(name)\n",
    "\n",
    "                company_address.append(address)\n",
    "\n",
    "                county_l.append(county)\n",
    "\n",
    "                employees_affected_l.append(employees_affected)\n",
    "\n",
    "                effective_date_l.append(effective_date)\n",
    "\n",
    "                closure_or_layoff_l.append(closure_or_layoff)\n",
    "\n",
    "            else:\n",
    "                name = result \n",
    "                error_name.append(name)\n",
    "                error_link.append(url)\n",
    "                continue\n",
    "    #create dataframe\n",
    "    d1 = {'url':urls, 'company_name': company_name, 'company_address': company_address, 'county': county_l, 'employees_affected': employees_affected_l, 'effective_date': effective_date_l, 'closure_or_layoff': closure_or_layoff_l}\n",
    "    df1 = pd.DataFrame(data=d1)\n",
    "    \n",
    "    #create error dataframe\n",
    "    d2 = {'links': error_link, 'name': error_name}\n",
    "    df2 = pd.DataFrame(data=d2)\n",
    "    df2 = df2.drop_duplicates()\n",
    "    print(url.split('/')[-1].split('.')[0]+' is done!')\n",
    "    return df1, df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March-2020 is done!\n",
      "February-2020 is done!\n",
      "January-2020 is done!\n",
      "December-2019 is done!\n",
      "November-2019 is done!\n",
      "October-2019 is done!\n",
      "September-2019 is done!\n",
      "August-2019 is done!\n",
      "July-2019 is done!\n",
      "June-2019 is done!\n",
      "May-2019 is done!\n",
      "April-2019 is done!\n",
      "March-2019 is done!\n",
      "February-2019 is done!\n",
      "January-2019 is done!\n",
      "December-2018 is done!\n",
      "November-2018 is done!\n",
      "October-2018 is done!\n",
      "September-2018 is done!\n",
      "August-2018 is done!\n",
      "July-2018 is done!\n",
      "June-2018 is done!\n",
      "May-2018 is done!\n",
      "April-2018 is done!\n",
      "March-2018 is done!\n",
      "February-2018 is done!\n",
      "January-2018 is done!\n",
      "December-2017 is done!\n",
      "November-2017 is done!\n",
      "October-2017 is done!\n",
      "September-2017 is done!\n",
      "August-2017 is done!\n",
      "July-2017 is done!\n",
      "June-2017 is done!\n",
      "May-2017 is done!\n",
      "April-2017 is done!\n",
      "March-2017 is done!\n",
      "February-2017 is done!\n",
      "January-2017 is done!\n",
      "December-2016 is done!\n",
      "November-2016 is done!\n",
      "October-2016 is done!\n",
      "September-2016 is done!\n",
      "August-2016 is done!\n",
      "July-2016 is done!\n",
      "June-2016 is done!\n",
      "May-2016 is done!\n",
      "April-2016 is done!\n",
      "March-2016 is done!\n",
      "February-2016 is done!\n",
      "January-2016 is done!\n",
      "December-2015 is done!\n",
      "November-2015 is done!\n",
      "October-2015 is done!\n",
      "September-2015 is done!\n",
      "August-2015 is done!\n",
      "July-2015 is done!\n",
      "June-2015 is done!\n",
      "May-2015 is done!\n",
      "April-2015 is done!\n",
      "March-2015 is done!\n",
      "February-2015 is done!\n",
      "January-2015 is done!\n",
      "December-2014 is done!\n",
      "November-2014 is done!\n",
      "October-2014 is done!\n",
      "September-2014 is done!\n",
      "August-2014 is done!\n",
      "July-2014 is done!\n",
      "June-2014 is done!\n",
      "May-2014 is done!\n",
      "April-2014 is done!\n",
      "March-2014 is done!\n",
      "February-2014 is done!\n",
      "January-2014 is done!\n",
      "December-2013 is done!\n",
      "November-2013 is done!\n",
      "October-2013 is done!\n",
      "September-2013 is done!\n",
      "August-2013 is done!\n",
      "July-2013 is done!\n",
      "June-2013 is done!\n",
      "May-2013 is done!\n",
      "April-2013 is done!\n",
      "March-2013 is done!\n",
      "February-2013 is done!\n",
      "January-2013 is done!\n",
      "December-2012 is done!\n",
      "November-2012 is done!\n",
      "October-2012 is done!\n",
      "September-2012 is done!\n",
      "August-2012 is done!\n",
      "July-2012 is done!\n",
      "June-2012 is done!\n",
      "May-2012 is done!\n",
      "April-2012 is done!\n",
      "March-2012 is done!\n",
      "February-2012 is done!\n",
      "January-2012 is done!\n",
      "December-2011 is done!\n",
      "November-2011 is done!\n",
      "October-2011 is done!\n",
      "September-2011 is done!\n",
      "August-2011 is done!\n",
      "July-2011 is done!\n",
      "June-2011 is done!\n",
      "May-2011 is done!\n",
      "April-2011 is done!\n",
      "March-2011 is done!\n",
      "February-2011 is done!\n",
      "January-2011 is done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dirs = \"./html\"\n",
    "if os.path.exists(dirs):\n",
    "    shutil.rmtree(dirs)\n",
    "os.makedirs(dirs)\n",
    "result_dirs = \"./results\"\n",
    "if os.path.exists(result_dirs):\n",
    "    shutil.rmtree(result_dirs)\n",
    "os.makedirs(result_dirs)\n",
    "df_lists = []\n",
    "df_error_lists = []\n",
    "for ele in month_links:#[98:110]:\n",
    "    #result = get_df(ele)\n",
    "    date = ele.split('/')[-1].split('.')[0]\n",
    "    #try:\n",
    "    result = get_df(ele)\n",
    "    sub_result_dirs = \"./results/\"+date+\"/\"\n",
    "    if os.path.exists(sub_result_dirs):\n",
    "        shutil.rmtree(sub_result_dirs)\n",
    "    os.makedirs(sub_result_dirs)\n",
    "    result[0].to_csv(\"./results/\"+date+\"/result.csv\", index = False)\n",
    "    result[1].to_csv(\"./results/\"+date+\"/error.csv\", index = False)\n",
    "    df_lists.append(result[0])\n",
    "    df_error_lists.append(result[1])\n",
    "    #except:\n",
    "        #print(ele)\n",
    "df1 = pd.concat(df_lists)\n",
    "df1.to_csv(\"final_result.csv\", index = False)\n",
    "df2 = pd.concat(df_error_lists)\n",
    "df2.to_csv(\"final_error.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
